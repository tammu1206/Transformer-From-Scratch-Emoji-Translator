# Transformer From Scratch: Emoji Translator ğŸ§ â¡ï¸ğŸ˜Š

This project is a minimal implementation of the legendary paper  
**"Attention Is All You Need"** â€” rebuilt from scratch in PyTorch.

## ğŸš€ What It Does
- Implements a Transformer (no HuggingFace, no shortcuts)
- Trains on toy data (English to emoji translation)
- Includes greedy decoding, beam search & top-k sampling
- Uses only basic PyTorch and torch.utils.data

## ğŸ§± Architecture
- Full encoder-decoder Transformer
- Multi-head attention, FFN, layer norm
- Custom tokenizer and dataloader
